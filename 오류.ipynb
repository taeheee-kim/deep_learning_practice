{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "예선 코드 정리.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOh33G4CeJ1bTyok5BlCDO4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "da8583a094924294956c7fa4f0758999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1e7ed22c1d894bdaac7b910fd539ddf6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a4a67286b8f340efb58f5c63c31c3ca8",
              "IPY_MODEL_30d186efb7a24a7493981393dda71830",
              "IPY_MODEL_ec4472846a034c8aa65ff8ffa45e8097"
            ]
          }
        },
        "1e7ed22c1d894bdaac7b910fd539ddf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4a67286b8f340efb58f5c63c31c3ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3026b801309e4232bdf7313295775ce8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_30fde4ee750b492ca113e8a12f684e4f"
          }
        },
        "30d186efb7a24a7493981393dda71830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_751b6d3f887a4ecd8a0985437f5ce0f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2079,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2079,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aa1ba5b5a33d40b0853a7de80472e369"
          }
        },
        "ec4472846a034c8aa65ff8ffa45e8097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_07e9a04d40694af681cc2082ccccd005",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2079/2079 [2:37:37&lt;00:00,  4.56s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f251983fdb841b1856d8684e5689fe4"
          }
        },
        "3026b801309e4232bdf7313295775ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "30fde4ee750b492ca113e8a12f684e4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "751b6d3f887a4ecd8a0985437f5ce0f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aa1ba5b5a33d40b0853a7de80472e369": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07e9a04d40694af681cc2082ccccd005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f251983fdb841b1856d8684e5689fe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taeheee-kim/deep_learning_practice/blob/master/%EC%98%A4%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPAiFmmDhclZ",
        "outputId": "cb4c02a7-1dbe-4c17-d158-396f9b18b138"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct 18 16:53:50 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P0    36W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBzsYbw-hiu-",
        "outputId": "b87498c1-1c82-4dff-a905-9e1c893e04d0"
      },
      "source": [
        "!pip install -q -U albumentations\n",
        "!echo \"$(pip freeze | grep albumentations) is successfully installed\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "albumentations==1.1.0 is successfully installed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgcQuNn9h8jn"
      },
      "source": [
        "### Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n22E0PBqhz7w",
        "outputId": "4575fbb3-9d8b-4fbf-e1f8-a03f0be705b2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QDiyS9ZiHTS"
      },
      "source": [
        "from collections import defaultdict\n",
        "import copy\n",
        "import random\n",
        "import os\n",
        "import shutil\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "import albumentations as A\n",
        "#from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn as nn\n",
        "import torch.optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "\n",
        "cudnn.benchmark = True\n",
        "\n",
        "import gc\n",
        "import torch\n",
        "import torch.utils.data as Data\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, models\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfP5AB5tmmE1"
      },
      "source": [
        "### Extract csv file from Image files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CBS0vPfiNEJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "99d718e2-48ea-4df0-dda0-0ef20459bf0b"
      },
      "source": [
        "# Extract csv file from Image files\n",
        "'''\n",
        "PATH = '/content/drive/MyDrive/Tomato/train_data/'\n",
        "\n",
        "\n",
        "file_list = ['Tomato_D01','Tomato_D04','Tomato_D05','Tomato_D07','Tomato_D08','Tomato_D09','Tomato_H','Tomato_P03','Tomato_P05','Tomato_R01'] #폴더 이름 리스트로!\n",
        "\n",
        "id = [] #이미지명\n",
        "label = [] #폴더 이름 = Tomato_D01\n",
        "\n",
        "for file_name in file_list : #D1, R1 10번 \n",
        "\n",
        "  file_path = os.path.join(PATH,file_name)\n",
        "  dir_list = os.listdir(file_path)\n",
        "\n",
        "  for j in range(len(dir_list)):  #1, 4, 6,10 ,100, 2115png\n",
        "    \n",
        "    id.append(dir_list[j].replace(\".png\",\"\"))\n",
        "    \n",
        "    label.append(file_name)\n",
        "\n",
        "df = pd.DataFrame({'file_name':id, 'class':label})\n",
        "df_shuffled=df.sample(frac=1).reset_index(drop=True) #순서 섞음\n",
        "\n",
        "df_shuffled\n",
        "'''"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nPATH = \\'/content/drive/MyDrive/Tomato/train_data/\\'\\n\\n\\nfile_list = [\\'Tomato_D01\\',\\'Tomato_D04\\',\\'Tomato_D05\\',\\'Tomato_D07\\',\\'Tomato_D08\\',\\'Tomato_D09\\',\\'Tomato_H\\',\\'Tomato_P03\\',\\'Tomato_P05\\',\\'Tomato_R01\\'] #폴더 이름 리스트로!\\n\\nid = [] #이미지명\\nlabel = [] #폴더 이름 = Tomato_D01\\n\\nfor file_name in file_list : #D1, R1 10번 \\n\\n  file_path = os.path.join(PATH,file_name)\\n  dir_list = os.listdir(file_path)\\n\\n  for j in range(len(dir_list)):  #1, 4, 6,10 ,100, 2115png\\n    \\n    id.append(dir_list[j].replace(\".png\",\"\"))\\n    \\n    label.append(file_name)\\n\\ndf = pd.DataFrame({\\'file_name\\':id, \\'class\\':label})\\ndf_shuffled=df.sample(frac=1).reset_index(drop=True) #순서 섞음\\n\\ndf_shuffled\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl7QYb1_mhiG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "74a67b0a-d5fd-43bc-d7f1-de851b756a2e"
      },
      "source": [
        "'''\n",
        "df = pd.get_dummies(df_shuffled['class'])\n",
        "id_sh = df_shuffled['file_name']\n",
        "df.insert(0,\"id\",id_sh,True)\n",
        "\n",
        "df.to_csv('/content/drive/MyDrive/Tomato/train.csv') #csv 파일 생성\n",
        "'''"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndf = pd.get_dummies(df_shuffled[\\'class\\'])\\nid_sh = df_shuffled[\\'file_name\\']\\ndf.insert(0,\"id\",id_sh,True)\\n\\ndf.to_csv(\\'/content/drive/MyDrive/Tomato/train.csv\\') #csv 파일 생성\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GYCbSn-mq4u"
      },
      "source": [
        "### Python File I/O"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhbXbjylmvfO"
      },
      "source": [
        "data_path = '/content/drive/MyDrive/Tomato/'\n",
        "\n",
        "train = pd.read_csv(data_path + 'train.csv')\n",
        "\n",
        "seed = 10\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.enabled = False"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MuGmA5-nANJ"
      },
      "source": [
        "### Split train and validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxS49H52mx1s"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "from torch.utils.data import Dataset  \n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "#device 설정 \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #device에 cuda 설정\n",
        "\n",
        "# Create train-validation split\n",
        "train, valid = train_test_split(train,\n",
        "                                test_size=0.1,\n",
        "                                stratify=train.loc[:, 'Tomato_D01':'Tomato_R01'],\n",
        "                                random_state=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2vIccfYnJ7y"
      },
      "source": [
        "### Create a custom dataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zbUC04FnHCU"
      },
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, df, img_dir='./', transform=None, is_test=False):\n",
        "        super().__init__()  \n",
        "        self.df = df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.is_test = is_test\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        img_id = self.df.iloc[idx, 0] \n",
        "        img_path = self.img_dir + str(img_id) + '.png'  #str 추가\n",
        "        image = cv2.imread(img_path) \n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
        "        \n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image=image)['image']\n",
        "\n",
        "        if self.is_test:\n",
        "            return image\n",
        "        else:\n",
        "            label = np.argmax(self.df.iloc[idx, 1:11]) #타겟 10개중 가장 큰 인덱스 반환\n",
        "            return image, label"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOKnV5yknU4V"
      },
      "source": [
        "### Define transform function(이미지 증강)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5plB6BxDnPFq"
      },
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "#from albumentations.pytorch import ToTensor"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFMD3ascnc2L"
      },
      "source": [
        "transform_tr = A.Compose([\n",
        "    A.Resize(400, 600), \n",
        "    A.RandomBrightnessContrast(brightness_limit=0.1, \n",
        "                               contrast_limit=0.1, p=0.5),\n",
        "    A.VerticalFlip(p=0.5), \n",
        "    A.HorizontalFlip(p=0.5), \n",
        "\n",
        "    A.ShiftScaleRotate(\n",
        "        shift_limit=0.1,\n",
        "        scale_limit=0.2,\n",
        "        rotate_limit=25, p=0.7),\n",
        "\n",
        "    A.OneOf([A.Emboss(p=1),\n",
        "             A.Sharpen(p=1),\n",
        "             A.Blur(p=1)], p=0.5),\n",
        "    A.PiecewiseAffine(p=0.5), \n",
        "    A.Normalize(), \n",
        "    ToTensorV2() \n",
        "    #ToTensor()\n",
        "])\n",
        "\n",
        "transform_te = A.Compose([\n",
        "    A.Resize(400, 600),\n",
        "    A.Normalize(),\n",
        "    ToTensorV2()\n",
        "    #ToTensor()\n",
        "])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgFW-e2jngfd"
      },
      "source": [
        "### seed worker 고정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeY0_V0wneg8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f894239-7c1f-44d2-c494-32a4efb63c04"
      },
      "source": [
        "def seed_worker(worker_id): \n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "    \n",
        "gen = torch.Generator()\n",
        "gen.manual_seed(0)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f5a737d9970>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKWCQ1zQnpWq"
      },
      "source": [
        "### Data 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XFuvSMYnkYi"
      },
      "source": [
        "from torch.utils.data import DataLoader \n",
        "\n",
        "batch_size = 6\n",
        "\n",
        "img_dir = '/content/drive/MyDrive/Tomato/images/'\n",
        "\n",
        "dataset_train = ImageDataset(train, img_dir=img_dir, transform=transform_tr)\n",
        "dataset_valid = ImageDataset(valid, img_dir=img_dir, transform=transform_te)\n",
        "\n",
        "\n",
        "loader_train = DataLoader(dataset_train, batch_size=batch_size, \n",
        "                          shuffle=True, worker_init_fn=seed_worker,\n",
        "                          generator=gen)\n",
        "loader_valid = DataLoader(dataset_valid, batch_size=batch_size, \n",
        "                          shuffle=False, worker_init_fn=seed_worker,\n",
        "                          generator=gen)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xyp_O4yntpz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3042f4c9-9dfd-49b2-8094-8782361e8d0f"
      },
      "source": [
        "!pip install efficientnet-pytorch==0.7.1"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: efficientnet-pytorch==0.7.1 in /usr/local/lib/python3.7/dist-packages (0.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet-pytorch==0.7.1) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet-pytorch==0.7.1) (3.7.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXC_4LxGn3Si",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1dd26d7-d88d-433c-adb6-3e1ff38ed844"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.11.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.19)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQtjG18pn8EG"
      },
      "source": [
        "### EfficientNet 모델 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFAQXQHbn5G7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0dd497a-c099-478c-e334-8481322610b0"
      },
      "source": [
        "from efficientnet_pytorch import EfficientNet \n",
        "\n",
        "model = EfficientNet.from_pretrained('efficientnet-b6', num_classes=10) \n",
        "\n",
        "model = model.to(device)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HkJ5Fl4oV_N"
      },
      "source": [
        "### Initialize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUCZLfVmoBwb"
      },
      "source": [
        "import torch.nn as nn \n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00007, weight_decay=0.0001)\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps=len(loader_train)*5, \n",
        "                                            num_training_steps=len(loader_train)*epochs)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQzkxAkVxkag"
      },
      "source": [
        "### 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-VPaIWtobcx"
      },
      "source": [
        "train_loss = []\n",
        "valid_loss = []\n",
        "train_acc = []\n",
        "val_acc = []"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN5pHu5FMZrg"
      },
      "source": [
        "#df_tl = pd.DataFrame (train_loss)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1wco4ZGLl7s"
      },
      "source": [
        "#path_tl = '/content/drive/My Drive/Tomato/태희/train_loss/tl'+ '.txt'\n",
        "#df_tl.to_csv(path_tl, sep = '\\t')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rccnLgvYMrRX"
      },
      "source": [
        "#print(type(df_tl))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo649W3toi_1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770,
          "referenced_widgets": [
            "da8583a094924294956c7fa4f0758999",
            "1e7ed22c1d894bdaac7b910fd539ddf6",
            "a4a67286b8f340efb58f5c63c31c3ca8",
            "30d186efb7a24a7493981393dda71830",
            "ec4472846a034c8aa65ff8ffa45e8097",
            "3026b801309e4232bdf7313295775ce8",
            "30fde4ee750b492ca113e8a12f684e4f",
            "751b6d3f887a4ecd8a0985437f5ce0f6",
            "aa1ba5b5a33d40b0853a7de80472e369",
            "07e9a04d40694af681cc2082ccccd005",
            "3f251983fdb841b1856d8684e5689fe4"
          ]
        },
        "outputId": "ce4ddcf2-3c3a-405a-dc79-c56c3c3caa34"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score # ROC AUC 점수 계산 함수\n",
        "from tqdm.notebook import tqdm # 진행률 표시 막대\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# 총 에폭만큼 반복\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    #train\n",
        "    model.train() # 모델을 훈련 상태로 설정\n",
        "    epoch_train_loss = 0 # 에폭별 손실값 초기화 (훈련 데이터용)\n",
        "    preds_for_acc = [] # 예측값\n",
        "    labels_for_acc = [] # 실제 값\n",
        "\n",
        "\n",
        "    # '반복 횟수'만큼 반복 \n",
        "    for images, labels in tqdm(loader_train):\n",
        "    \n",
        "        # 이미지, 레이블(타깃 값) 데이터 미니배치를 장비에 할당 \n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # 옵티마이저 내 기울기 초기화\n",
        "        optimizer.zero_grad()\n",
        "        # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n",
        "        outputs = model(images)\n",
        "        # 손실함수를 활용해 outputs와 labels의 손실값 계산\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 현재 배치에서의 손실 추가 (훈련 데이터용)\n",
        "        epoch_train_loss += loss.item() \n",
        "        # 영어 코드에서는 loss.item()에 labels.shape[0]을 곱해주는데 이건 왜 그러는지 모르겠넹\n",
        "\n",
        "        # 역전파 수행\n",
        "        loss.backward() \n",
        "        # 가중치 갱신\n",
        "        optimizer.step() \n",
        "        # 스케줄러 학습률 갱신\n",
        "        scheduler.step() \n",
        "\n",
        "        #영어 코드 복붙\n",
        "        labels_for_acc = np.concatenate((labels_for_acc, labels.cpu().numpy()),0)\n",
        "        preds_for_acc = np.concatenate((preds_for_acc, np.argmax(outputs.cpu().detach().numpy(),1)),0)\n",
        "        \n",
        "        path = '/content/drive/My Drive/Tomato/태희/epoch_예선_CHECK' + str(epoch) + '.pt'\n",
        "        torch.save(model.state_dict(), path)\n",
        "\n",
        "    ta = accuracy_score(labels_for_acc, preds_for_acc)\n",
        "    tl = epoch_train_loss/len(loader_train)\n",
        "\n",
        "    # 훈련 데이터 손실값 출력\n",
        "    print(f'에폭 [{epoch+1}/{epochs}] - 훈련 데이터 손실값 : {epoch_train_loss/len(loader_train):.4f}')\n",
        "    \n",
        "\n",
        "    # validation\n",
        "    \n",
        "    model.eval() # 모델을 평가 상태로 설정 \n",
        "    epoch_valid_loss = 0 # 에폭별 손실값 초기화 (검증 데이터용) \n",
        "    preds_list = [] # 예측 확률값 저장용 리스트 초기화 \n",
        "    true_list = [] # 실제 타깃 값 저장용 리스트 초기화 \n",
        "    \n",
        "\n",
        "    with torch.no_grad(): # 기울기 계산 비활성\n",
        "        for images, labels in loader_valid:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            epoch_valid_loss += loss.item()\n",
        "            \n",
        "            true_list = np.concatenate((true_list, labels.cpu().numpy()),0)\n",
        "            preds_list = np.concatenate((preds_list, np.argmax(outputs.cpu().detach().numpy(),1)),0)\n",
        "\n",
        "            va = accuracy_score(true_list, preds_list)\n",
        "            vl = epoch_valid_loss/len(loader_valid)\n",
        "            \n",
        "            \n",
        "        # 검증 데이터 손실값 및 ROC AUC 점수 출력 \n",
        "        print(f'에폭 [{epoch+1}/{epochs}] - 검증 데이터 손실값 : {epoch_valid_loss/len(loader_valid):.4f} / 검증 데이터 ROC AUC : {roc_auc_score(true_list, preds_list):.4f}')  \n",
        "\n",
        "    train_loss.append(t1)\n",
        "    valid_loss.append(v1)\n",
        "    train_acc.append(ta)\n",
        "    val_acc.append(va)\n",
        "\n",
        "    df_tl = pd.DataFrame (train_loss)\n",
        "    df_vl = pd.DataFrame (valid_loss)\n",
        "    df_ta = pd.DataFrame (train_acc)\n",
        "    df_va = pd.DataFrame (val_acc)\n",
        "\n",
        "    path_tl = '/content/drive/My Drive/Tomato/태희/train_loss/tl' + str(epoch) + '.txt'\n",
        "    df_tl.to_csv(path_tl, sep = '\\t')\n",
        "    path_vl = '/content/drive/My Drive/Tomato/태희/valid_loss/vl' + str(epoch) + '.txt'\n",
        "    df_vl.to_csv(path_vl, sep = '\\t')\n",
        "    path_ta = '/content/drive/My Drive/Tomato/태희/train_acc/ta' + str(epoch) + '.txt'\n",
        "    df_ta.to_csv(path_ta, sep = '\\t')\n",
        "    path_va = '/content/drive/My Drive/Tomato/태희/val_acc/va' + str(epoch) + '.txt'\n",
        "    df_va.to_csv(path_va, sep = '\\t')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da8583a094924294956c7fa4f0758999",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2079 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에폭 [1/3] - 훈련 데이터 손실값 : 1.1050\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-44ad2a5c63ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# 검증 데이터 손실값 및 ROC AUC 점수 출력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'에폭 [{epoch+1}/{epochs}] - 검증 데이터 손실값 : {epoch_valid_loss/len(loader_valid):.4f} / 검증 데이터 ROC AUC : {roc_auc_score(true_list, preds_list):.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    388\u001b[0m                                              max_fpr=max_fpr),\n\u001b[1;32m    389\u001b[0m                                      \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                                      sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    391\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# multilabel-indicator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         return _average_binary_score(partial(_binary_roc_auc_score,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;34m\"\"\"Binary roc auc score\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[1;32m    222\u001b[0m                          \"is not defined in that case.\")\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6HSbKK6xotn"
      },
      "source": [
        "### Epoch에 따른 Train vs Val 손실값 비교"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q_j5VGuomSB"
      },
      "source": [
        "plt.figure()\n",
        "plt.ylim(0,1.5)\n",
        "sns.lineplot(list(range(len(train_loss))), train_loss)\n",
        "sns.lineplot(list(range(len(valid_loss))), valid_loss)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(['Train','Val'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk0ciA_jxxc-"
      },
      "source": [
        "### Epoch에 따른 Train vs Val 정확도 비교"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77pCay0ComUm"
      },
      "source": [
        "plt.figure()\n",
        "sns.lineplot(list(range(len(train_acc))), train_acc)\n",
        "sns.lineplot(list(range(len(val_acc))), val_acc)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train','Val'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT2x_EVPx4fe"
      },
      "source": [
        "### 저장된 모델 불러와서 TTA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2m0KE0vxhm5"
      },
      "source": [
        "#저장된 Model load\n",
        "'''\n",
        "PATH = '/content/drive/MyDrive/Tomato/태희/'\n",
        "\n",
        "model = EfficientNet.from_pretrained('efficientnet-b6', num_classes=10)\n",
        "\n",
        "device = 'cuda'\n",
        "model.load_state_dict(copy.deepcopy(torch.load(PATH + \"epoch수정12.pt\",device))) # 9, 14, 19, 24, 29 \n",
        "\n",
        "model = model.to(device) \n",
        "\n",
        "batch_size = 6\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-3wFgiHx8Y8"
      },
      "source": [
        "'''\n",
        "data_path = '/content/drive/MyDrive/Tomato/'\n",
        "\n",
        "test = pd.read_csv(data_path + 'test.csv')\n",
        "submission = pd.read_csv(data_path + 'sample_submission.csv')\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NOYEu2Dx960"
      },
      "source": [
        "#data loader 설정 및 tta 학습\n",
        "'''\n",
        "img_dir = '/content/drive/My Drive/Tomato/test_images/'\n",
        "\n",
        "dataset_TTA = ImageDataset(test, img_dir=img_dir, \n",
        "                           transform=transform_tr, is_test=True)\n",
        "loader_TTA = DataLoader(dataset_TTA, batch_size=batch_size, \n",
        "                        shuffle=False, worker_init_fn=seed_worker,\n",
        "                        generator=gen)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vswlKf8x-_n"
      },
      "source": [
        "'''\n",
        "num_TTA = 3\n",
        "\n",
        "preds_tta = np.zeros((len(test), 10)) \n",
        "\n",
        "for i in range(num_TTA):\n",
        "    print(i+1, \"회입니다.\")\n",
        "    with torch.no_grad():\n",
        "        for i, images in enumerate(loader_TTA):\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "\n",
        "            preds_part = torch.softmax(outputs.cpu(), dim=1).squeeze().numpy()\n",
        "            preds_tta[i*batch_size:(i+1)*batch_size] += preds_part\n",
        "            '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp7gYh87yBQl"
      },
      "source": [
        "'''preds_tta /= num_TTA '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmtZNm_lyCCY"
      },
      "source": [
        "#submission_csv 파일 저장 및 제출\n",
        "'''\n",
        "submission_tta = submission.copy() \n",
        "\n",
        "submission_tta[['Tomato_D01','Tomato_D04','Tomato_D05','Tomato_D07','Tomato_D08','Tomato_D09','Tomato_H','Tomato_P03','Tomato_P05','Tomato_R01']] = preds_tta\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sboeaB14yCt-"
      },
      "source": [
        "'''submission_tta'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfMzj-CgyDbq"
      },
      "source": [
        "'''id = submission_tta[\"file_name\"]'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_gksTewyES2"
      },
      "source": [
        "'''pred_idx = np.argmax(preds_tta, axis=1)  #확률 중 가장 높은 값의 인덱스를 0 ~ 9까지 반환'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fNkW1wDyFGq"
      },
      "source": [
        "#pred_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zuq6a_DjyF5o"
      },
      "source": [
        "#df = pd.DataFrame({'file_name':id, 'answer':pred_idx})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM-E9z-qyHva"
      },
      "source": [
        "#df "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phvZ_vP6yITg"
      },
      "source": [
        "#df.to_csv('/content/drive/MyDrive/Tomato/현중/최종.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}